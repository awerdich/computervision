{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b8c7ba-53b2-4b86-86e1-db2ab56e4d61",
   "metadata": {},
   "source": [
    "### Inference on a larger data set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c792a7e0-6b93-45a9-bc77-17378d1a7122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project version: v0.0.2\n",
      "Python version:  3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as alb\n",
    "import itertools\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import ops\n",
    "\n",
    "# Hugging Face Library\n",
    "from transformers import RTDetrV2ForObjectDetection, RTDetrImageProcessor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import computervision\n",
    "from computervision.imageproc import is_image, ImageData, clipxywh, xyxy2xywh, xywh2xyxy\n",
    "from computervision.imageproc import plot_boxes\n",
    "from computervision.datasets import DETRdataset, get_gpu_info\n",
    "from computervision.transformations import AugmentationTransform\n",
    "from computervision.performance import DetectionMetrics\n",
    "from computervision.inference import DETR\n",
    "\n",
    "print(f'Project version: {computervision.__version__}')\n",
    "print(f'Python version:  {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363ffa48-4716-4e20-a169-09cc97360393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs found:  1\n",
      "Current device ID: 0\n",
      "GPU device name:   NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "PyTorch version:   2.8.0a0+34c6371d24.nv25.08\n",
      "CUDA version:      13.0\n",
      "CUDNN version:     91200\n",
      "Device for model training/inference: cuda:0\n",
      "Current device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device, device_str = get_gpu_info()\n",
    "print(f'Current device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dbdf0a9-892d-425e-a593-86faffc8f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and files\n",
    "dataset = 'dataset_object_roboflow_240930'\n",
    "annotations_file_name = 'roboflow_240930_dset.parquet'\n",
    "image_dir = os.path.join(os.environ.get('DATA'), dataset)\n",
    "annotations_file = os.path.join(image_dir, annotations_file_name)\n",
    "\n",
    "file_col = 'multi_file'\n",
    "bbox_col = 'bbox'\n",
    "pos_col = 'pos'\n",
    "\n",
    "model_name = 'rtdetr_roboflow_251005_01'\n",
    "model_dir = os.path.join(os.environ.get('DATA'), 'model', model_name)\n",
    "checkpoint = 'checkpoint-3800'\n",
    "checkpoint_dir = os.path.join(model_dir, checkpoint)\n",
    "\n",
    "results_dir = os.path.join(model_dir, 'results')\n",
    "Path(results_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4809577-6fc3-494f-a234-a0fbbd61d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbox_format', 'id2label', 'model_info', 'processor_params', 'training_args']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>license</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name_hash</th>\n",
       "      <th>dset</th>\n",
       "      <th>multi_file</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category</th>\n",
       "      <th>disease</th>\n",
       "      <th>pos</th>\n",
       "      <th>box_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pbws-super-set-1-completed__PBWs_Super_Set_3-0...</td>\n",
       "      <td>480</td>\n",
       "      <td>640</td>\n",
       "      <td>2024-09-17T23:44:33+00:00</td>\n",
       "      <td>eb79ef10bf</td>\n",
       "      <td>val</td>\n",
       "      <td>eb79ef10bf.jpg</td>\n",
       "      <td>[0.0, 1.0, 128.205, 159.0]</td>\n",
       "      <td>tooth 24</td>\n",
       "      <td>teeth</td>\n",
       "      <td>12</td>\n",
       "      <td>eb79ef10bf_16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pbws-super-set-1-completed__PBWs_Super_Set_3-0...</td>\n",
       "      <td>480</td>\n",
       "      <td>640</td>\n",
       "      <td>2024-09-17T23:44:33+00:00</td>\n",
       "      <td>eb79ef10bf</td>\n",
       "      <td>val</td>\n",
       "      <td>eb79ef10bf.jpg</td>\n",
       "      <td>[121.0, 4.0, 230.744, 167.0]</td>\n",
       "      <td>tooth 25</td>\n",
       "      <td>teeth</td>\n",
       "      <td>13</td>\n",
       "      <td>eb79ef10bf_17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  license                                          file_name  height  \\\n",
       "0   2        1  pbws-super-set-1-completed__PBWs_Super_Set_3-0...     480   \n",
       "1   2        1  pbws-super-set-1-completed__PBWs_Super_Set_3-0...     480   \n",
       "\n",
       "   width              date_captured file_name_hash dset      multi_file  \\\n",
       "0    640  2024-09-17T23:44:33+00:00     eb79ef10bf  val  eb79ef10bf.jpg   \n",
       "1    640  2024-09-17T23:44:33+00:00     eb79ef10bf  val  eb79ef10bf.jpg   \n",
       "\n",
       "                           bbox  category disease  pos         box_id  label  \n",
       "0    [0.0, 1.0, 128.205, 159.0]  tooth 24   teeth   12  eb79ef10bf_16     11  \n",
       "1  [121.0, 4.0, 230.744, 167.0]  tooth 25   teeth   13  eb79ef10bf_17     12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model configuration files\n",
    "config_file = os.path.join(model_dir, f'{model_name}.json')\n",
    "with open(config_file, mode='r') as fl:\n",
    "    model_config = json.load(fl)\n",
    "display(sorted(list(model_config.keys())))\n",
    "\n",
    "# Annotations for the test set\n",
    "df = pd.read_parquet(annotations_file).astype({'pos': int})\n",
    "df = df.loc[df['dset'].isin(['val', 'test'])].reset_index(drop=True)\n",
    "\n",
    "# Labels: Convert the model's label id's into tooth positions\n",
    "id2label = model_config.get('id2label')\n",
    "id2label = {int(k): int(v) for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "df = df.assign(label=df[pos_col].apply(lambda pos: label2id.get(pos)))\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7adcc2-007a-4f3f-acc7-ea975a4b58e0",
   "metadata": {},
   "source": [
    "### Load the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594b699d-3b70-4ef4-8ad6-7f9b27394a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = RTDetrImageProcessor.from_pretrained(checkpoint_dir)\n",
    "model = RTDetrV2ForObjectDetection.from_pretrained(checkpoint_dir).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd9b9e-49c7-4cd8-8ded-79e511d80c6c",
   "metadata": {},
   "source": [
    "### Create the data set and the data loader for running predictions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb24cba-c17d-4acd-9335-b921cdb359b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in data set:  96\n",
      "Batch size:                    4\n",
      "Number of batches in data set: 24\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collates a batch of data samples into a single dictionary for model input.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data[\"pixel_values\"] = torch.stack([x[\"pixel_values\"] for x in batch]).to(device)\n",
    "    data[\"labels\"] = [x[\"labels\"].to(device) for x in batch]\n",
    "    return data\n",
    "\n",
    "dataset = DETRdataset(data=df.copy(),\n",
    "                      image_processor=processor,\n",
    "                      image_dir=image_dir,\n",
    "                      file_name_col=file_col,\n",
    "                      label_id_col='label',\n",
    "                      bbox_col=bbox_col,\n",
    "                      transforms=[alb.NoOp()])\n",
    "\n",
    "batch_size = 4\n",
    "dl = DataLoader(dataset=dataset, batch_size=4, collate_fn=collate_fn)\n",
    "\n",
    "# Calculate the number of batches in the data set\n",
    "n_images = len(dataset)\n",
    "n_batches = int(np.floor(n_images / batch_size))\n",
    "rest = int(n_images - (n_batches * batch_size))\n",
    "if rest > 0:\n",
    "    n_batches += 1\n",
    "print(f'Number of images in data set:  {n_images}')\n",
    "print(f'Batch size:                    {batch_size}')\n",
    "print(f'Number of batches in data set: {n_batches}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac95fa3-441b-4c17-9933-b8b14f74687b",
   "metadata": {},
   "source": [
    "### Predict on the data set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf83b3c-6d1c-425a-b1ae-f10278a57e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(batch, threshold):\n",
    "    # Predict on the batch and process the output\n",
    "    image_id_list = [int(label.get('image_id').cpu()) for label in batch['labels']]\n",
    "    target_size_list = [label.get('orig_size') for label in batch['labels']]\n",
    "    image_size_list = [tuple(s.cpu().numpy()) for s in target_size_list]\n",
    "    target_sizes = torch.stack(target_size_list)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        output_batch = processor.post_process_object_detection(outputs=outputs, \n",
    "                                                               target_sizes=target_sizes, \n",
    "                                                               threshold=threshold)\n",
    "    pred_df_image_list = []\n",
    "    for i, image_id in enumerate(image_id_list):\n",
    "        x_lim, y_lim = (0, image_size_list[i][1]), (0, image_size_list[i][0])\n",
    "        score_list = output_batch[i].get('scores').cpu().numpy()\n",
    "        label_list = output_batch[i].get('labels').cpu().numpy()\n",
    "        pos_list = [id2label.get(cl) for cl in label_list] \n",
    "        box_list = output_batch[i].get('boxes').cpu().numpy()\n",
    "        box_list = [clipxywh(xyxy2xywh(list(box)), xlim=x_lim, ylim=y_lim, decimals=0) for box in box_list]\n",
    "        box_area_list = [box[2] * box[3] for box in box_list]\n",
    "        pred_dict = {pos_col: pos_list, bbox_col: box_list, 'score': score_list, 'area': box_area_list}\n",
    "        pred_df = pd.DataFrame(pred_dict)\n",
    "        pred_df.insert(loc=0, column='image_id', value=image_id)\n",
    "        pred_df_image_list.append(pred_df)\n",
    "    pred_batch = pd.concat(pred_df_image_list, axis=0, ignore_index=True)\n",
    "    return pred_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874df7c0-b52c-4eaf-aced-a243fe9cc2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 5 / 24\n",
      "Running batch 10 / 24\n",
      "Running batch 15 / 24\n",
      "Running batch 20 / 24\n"
     ]
    }
   ],
   "source": [
    "# Predict on the data set\n",
    "threshold = 0.05\n",
    "pred_df_list = []\n",
    "for b, batch in enumerate(dl):\n",
    "    if (b +1) % 5 == 0:\n",
    "        print(f'Running batch {b + 1} / {n_batches}')\n",
    "    pred_df_list.append(predict_batch(batch, threshold=threshold))\n",
    "pred_df = pd.concat(pred_df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4d3e5d-13dc-4d70-bfe3-8bb7ed33721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>bbox</th>\n",
       "      <th>score</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[385, 155, 254, 204]</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>51816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[212, 161, 393, 198]</td>\n",
       "      <td>0.973566</td>\n",
       "      <td>77814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>[96, 153, 204, 206]</td>\n",
       "      <td>0.973493</td>\n",
       "      <td>42024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[391, 1, 249, 145]</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>36105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[225, 3, 399, 139]</td>\n",
       "      <td>0.067809</td>\n",
       "      <td>55461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  pos                  bbox     score   area\n",
       "0         0   18  [385, 155, 254, 204]  0.984009  51816\n",
       "1         0   19  [212, 161, 393, 198]  0.973566  77814\n",
       "2         0   20   [96, 153, 204, 206]  0.973493  42024\n",
       "3         0   15    [391, 1, 249, 145]  0.069184  36105\n",
       "4         0   14    [225, 3, 399, 139]  0.067809  55461"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410f48b6-948e-40d2-88eb-9e7d20b3937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_df['image_id'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
